---
title: "Iowa Probation Project"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if(!require(ggplot2)){install.packages('ggplot2')}
if(!require(lubridate)){install.packages('lubridate')}
if(!require(ggthemes)){install.packages('ggthemes')}
if(!require(dplyr)){install.packages('dplyr')}
if(!require(caret)){install.packages('caret')}
if(!require(kknn)){install.packages('kknn')}
if(!require(nnet)){install.packages('nnet')}
if(!require(randomForest)){install.packages('randomForest')}
if(!require(e1071)){install.packages('e1071')}
if(!require(adabag)){install.packages('adabag')}
if(!require(gridExtra)){install.packages('grid_Extra')}
if(!require(outliers)){install.packages('outliers')}
if(!require(psych)){install.packages('psych')}
if(!require(stats)){install.packages('stats')}

library(ggplot2)
library(lubridate)
library(ggthemes)
library(dplyr)
library(caret)
library(kknn)
library(nnet)
library(randomForest)
library(e1071)
library(adabag)
library(gridExtra)
library(outliers)
library(psych)
library(stats)

#Importing needed datasets
prob <- read.csv("3-Year_Recidivism_for_Offenders_Admitted_to_Probation_in_Iowa.csv")
```

## Predicting Probation Recidivisim

When taking a look at our probation data I see only one instance where data wrangling is necessary.  Probation recidivism is broken into two types, new charge and technical violation. For our purposes we will combine these two types of re-offense and create a new variable simply expressing the whether or not recidivism occurred as a yes or no.  Below you can see how many instances of re-offense happened both before and after the change.
```{r, echo=FALSE}
#Analyzing types of recidivism for probationers
table(prob$Recidivism.Type)

prob$Recidivist <- as.factor(ifelse(prob$Recidivism.Type=='New Charge','Yes',ifelse(prob$Recidivism.Type=='Technical Violation','Yes','No')))

table(prob$Recidivist)
```

Next I am going to reflect which variables within this new dataset are going to be the most important in predicting whether or not a probationer will re-offend.  I will be doing this using a random forest model, the variable importance function and will also chart it.
```{r, echo=FALSE}
#Selecting columns necessary for modeling
probu <- prob %>% select(Sex,Race...Ethnicity,Offense.Classification,Offense.Type,Offense.Subtype,Supervision.Level,Recidivist)

head(probu)

#Creating model to show variable importance and charting it
set.seed(2020)
modelz <- randomForest(Recidivist ~ ., data=probu,family=binomial)

Vz <- varImp(modelz)

ggplot2::ggplot(Vz, aes(x=reorder(rownames(Vz),Overall), y=Overall)) +
  geom_point( color="blue", size=4, alpha=0.6)+
  geom_segment( aes(x=rownames(Vz), xend=rownames(Vz), y=0, yend=Overall), 
                color='skyblue') +
  xlab('Variable')+
  ylab('Overall Importance')+
  theme_light() +
  coord_flip() 
```

```{r, echo=FALSE}
#Partitioning data for testing
set.seed(2020)
partyz <- createDataPartition(probu[,"Recidivist"],times=1,p=0.8,list=FALSE)
trainz <- probu[partyz,]
testz <- probu[-partyz,]

#Creating Duplicate Partitions
trainz1 <- trainz
trainz2 <- trainz
trainz3 <- trainz

testz1 <- testz
testz2 <- testz 
testz3 <- testz
```

After various models I have found that our best model is a naive Bayes model.  While random forest produced a better overall accuracy I noticed that the vast majority of cases in our data did not involve recidivism and figured I needed to not only check our model's overall accuracy but also check its accuracy when predicting that a probationer would re-offend.  Our naive Bayes model fuctioned the best when taking into account both of these acccuracies. 

Here I will present our naive Bayes model and both it's overall accuracy and it's accuracy in predicting positive results. 
```{r, echo=FALSE}
#naive Bayes
set.seed(2020)
modelz2 <- naiveBayes(Recidivist ~ .,data=trainz2)

predz2 <- predict(modelz2,newdata=testz2)

testz2$predz <- predz2

testz2$score <- ifelse(testz2$predz==testz2$Recidivist,'good prediction','bad prediction')

cat(paste('Accuracy =',round(mean(predz2==testz2$Recidivist),3)))

table(testz2$score)

testz2i <- testz2 %>% filter(testz2$Recidivist=='Yes')

cat(paste("Accuracy of 'Yes' Predictions  =",round(mean(testz2i$predz==testz2i$Recidivist),3)))

table(testz2i$score)
```

Here we have very positive results in our naive Bayes model.  With the given data we are able to predict with 86% overall accuracy whether or not an offender will re-offend and 49% accuracy in predicting that a probationer will re-offend.

The other two models I ran were random forest and neural net models.  They did not function as well as our naive Bayes model, but I have included their performances below.  

#### Random Forest
```{r, echo=FALSE}
#Random Forest 
set.seed(2020)
modelz1 <- randomForest(Recidivist ~ .,data=trainz1,family=binomial)

predz1 <- predict(modelz1,newdata=testz1,type='response')

testz1$predz <- as.factor(predz1)

testz1$score <-ifelse(testz1$predz==testz1$Recidivist,'good prediction','bad prediction')

cat(paste('Accuracy =',round(mean(predz1==testz1$Recidivist),3)))

table(testz1$score)

testz1i <- testz1 %>% filter(testz1$Recidivist=='Yes')

cat(paste("Accuracy of 'Yes' Predictions  =",round(mean(testz1i$predz==testz1i$Recidivist),3)))

table(testz1i$score)
```

#### Neural Net
```{r, echo=FALSE}
#Neural Net
set.seed(2020)
modelz3 <- multinom(Recidivist ~ .,data=trainz3)

predz3 <- predict(modelz3,newdata=testz3)

testz3$predz <- predz3

testz3$score <- ifelse(testz3$predz==testz3$Recidivist,'good prediction','bad prediction')

cat(paste('Accuracy =',round(mean(predz3==testz3$Recidivist),3)))

table(testz3$score)

testz3i <- testz3 %>% filter(testz3$Recidivist=='Yes')

cat(paste("Accuracy of 'Yes' Predictions  =",round(mean(testz3i$predz==testz3i$Recidivist),3)))

table(testz3i$score)
```

In conclusion, I recognize fully that when predicting something like this plugging an individual offender's data into my model would not be the only tool necessary in making the decision of whether they should go on probation or go to prison.  I am, however, fully confident that our naive Bayes model is a great way to get some objective insight into the chances of recidivism for those making the sentencing decision.
