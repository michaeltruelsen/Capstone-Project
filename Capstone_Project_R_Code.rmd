---
title: "Iowa Probation Project"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if(!require(ggplot2)){install.packages('ggplot2')}
if(!require(lubridate)){install.packages('lubridate')}
if(!require(ggthemes)){install.packages('ggthemes')}
if(!require(dplyr)){install.packages('dplyr')}
if(!require(caret)){install.packages('caret')}
if(!require(kknn)){install.packages('kknn')}
if(!require(nnet)){install.packages('nnet')}
if(!require(randomForest)){install.packages('randomForest')}
if(!require(e1071)){install.packages('e1071')}
if(!require(adabag)){install.packages('adabag')}
if(!require(gridExtra)){install.packages('grid_Extra')}
if(!require(outliers)){install.packages('outliers')}
if(!require(psych)){install.packages('psych')}
if(!require(stats)){install.packages('stats')}

library(ggplot2)
library(lubridate)
library(ggthemes)
library(dplyr)
library(caret)
library(kknn)
library(nnet)
library(randomForest)
library(e1071)
library(adabag)
library(gridExtra)
library(outliers)
library(psych)
library(stats)

#Importing needed datasets
prob <- read.csv("3-Year_Recidivism_for_Offenders_Admitted_to_Probation_in_Iowa.csv")
```

## Predicting Probation Recidivisim

When taking a look at our probation data I see only one instance where data wrangling is necessary.  Probation recidivism is broken into two types, new charge and technical violation. For our purposes we will combine these two types of re-offense and create a new variable simply expressing the whether or not recidivism occurred as a yes or no.  Below you can see how many instances of re-offense happened both before and after the change.
```{r}
#Analyzing types of recidivism for probationers
table(prob$Recidivism.Type)

prob$Recidivist <- as.factor(ifelse(prob$Recidivism.Type=='New Charge','Yes',ifelse(prob$Recidivism.Type=='Technical Violation','Yes','No')))

table(prob$Recidivist)
```

Next I am going to reflect which variables within this new dataset are going to be the most important in predicting whether or not a probationer will re-offend.  I will be doing this using a random forest model, the variable importance function and will also chart it.
```{r}
#Selecting columns necessary for modeling
probu <- prob %>% select(Sex,Race...Ethnicity,Offense.Classification,Offense.Type,Offense.Subtype,Supervision.Level,Recidivist)

head(probu)

#Creating model to show variable importance and charting it
set.seed(2020)
modelz <- randomForest(Recidivist ~ ., data=probu,family=binomial)

Vz <- varImp(modelz)

ggplot2::ggplot(Vz, aes(x=reorder(rownames(Vz),Overall), y=Overall)) +
  geom_point( color="blue", size=4, alpha=0.6)+
  geom_segment( aes(x=rownames(Vz), xend=rownames(Vz), y=0, yend=Overall), 
                color='skyblue') +
  xlab('Variable')+
  ylab('Overall Importance')+
  theme_light() +
  coord_flip() 
```

Next up I will be partitioning the data from our new dataset into training and testing partitions and then making multiple iterations of these partitions to facilitate testing several different models.
```{r}
#Partitioning data for testing
set.seed(2020)
partyz <- createDataPartition(probu[,"Recidivist"],times=1,p=0.8,list=FALSE)
trainz <- probu[partyz,]
testz <- probu[-partyz,]

#Creating Duplicate Partitions
trainz1 <- trainz
trainz2 <- trainz
trainz3 <- trainz

testz1 <- testz
testz2 <- testz 
testz3 <- testz
```

After various models I have found that our best model is a naive Bayes model.  While our random forest and neural net models produced a better overall accuracy I noticed that the vast majority of cases in our data did not involve recidivism and figured I needed to not only take into account our model's overall accuracy but also its accuracy when predicting that a probationer would re-offend.  Our naive Bayes model functioned the best when taking into account both of these accuracy metrics. 

Here I will present our naive Bayes model and both it's overall accuracy and it's accuracy in predicting positive results. 
```{r}
#naive Bayes
set.seed(2020)
modelz2 <- naiveBayes(Recidivist ~ .,data=trainz2)

predz2 <- predict(modelz2,newdata=testz2)

testz2$predz <- predz2

confusionMatrix(testz2$Recidivist,testz2$predz)
```

Here we have very positive results in our naive Bayes model.  With the given data we are able to predict re-offense with an accuracy of 86%.  Our confusion matrix also tells us that 93.2% of our re-offenders were correctly classified as such.  Given our objective and the nature of our test I think this metric is worth noting.

The other two models I ran were random forest and neural net models.  They did not function as well as our naive Bayes model, but I have included their performances below.  

#### Random Forest
```{r}
#Random Forest 
set.seed(2020)
modelz1 <- randomForest(Recidivist ~ .,data=trainz1,family=binomial)

predz1 <- predict(modelz1,newdata=testz1,type='response')

testz1$predz <- as.factor(predz1)

confusionMatrix(testz1$Recidivist,testz1$predz)
```

#### Neural Net
```{r}
#Neural Net
set.seed(2020)
modelz3 <- multinom(Recidivist ~ .,data=trainz3)

predz3 <- predict(modelz3,newdata=testz3)

testz3$predz <- predz3

confusionMatrix(testz3$Recidivist,testz3$predz)45
```

In conclusion, I recognize fully that when predicting something like this plugging an individual offender's data into my model would not be the only tool necessary in making the decision of whether they should go on probation or go to prison.  I am, however, fully confident that our naive Bayes model is a great way to get some objective insight into the chances of recidivism for those making the sentencing decision.
